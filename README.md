# MachineLearning
My primitive library for machine learning algorithms

1_2task folder contain:

This project include metric classification and SVM algorithm for two classes of colour dots. 

run.py - include matplotlib figure and initiate main script

top_class.py - a main metaclass, that includes coordinates and colour of dots and inherit other classes

init_dots.py - creates random normalvariate dots

range_algorithm.py - metric k-nearest neighbors algorithm with Parsen's window

svm_algorithm.py - SVM method have many issues

Условия всех задач:

Задача 1: Сгенерировать два случайных, частично перекрывающихся распределения для объектов на двумерном вещественном пространстве {R,R}. Признаками объектов будем считать их координаты. Первое множество назовем классом 1, а второе множество - классом объектов 2. Нужно нарисовать карту машинной классификации для области пространства, окружающей объекты, где классификация делается методом поиска нескольких ближайших соседей с убывающими весами. На карте цветовой шкалой должно быть отмечена вероятность отнесения к классу 1 или 2. Поверх должны быть показаны объекты обучающей выборки, помеченные разными цветами, соответствующими классам.

Задача 2: Взять два класса из задачи 1 с теми же признаками. Обучить классификатор SVM (на основе опорных векторов), используя обычное ядро скалярного произведения и гауссово ядро. Подобрать параметры классификатора и обосновать их выбор. Для каждого ядра нарисовать карту машинной классификации для области пространства, окружающей объекты. На карте двумя цветами или контурной линией должна быть отмечена зона отнесения к классу 1 или -1. Поверх должны быть показаны объекты обучающей выборки, так, чтобы среди них выделялись опорные объекты, а каждый класс помечался своим цветом. Для отмечания опорных объектов можно использовать размер точек.

Задача 3: Скачать файл (http://download.ximc.ru/Machine%20learning/MLT3%202016-10-18%2010-04-34%20objects.csv), где дана выборка объектов, признаками которых является многомерный вектор в пространстве действительных чисел, а ответом одномерное действительное число. Объекты сохранены в csv формате, где каждый объект представлен строкой. Все числовые значения, кроме последнего это признаки объекта, а последнее значение это ответ объекта. Известно, что ответ объекта приблизительно равен некой линейной комбинации признаков объекта. Нужно решить задачу многомерной линейной регрессии по 75% выборки с контролем качества по 25% выборки.

Задача 4: Решить задачу прогнозирования временных рядов. Для этого взять исторические данные по любой торговле (курсы валют, акций, криптовалюты…), например по ссылке http://api.bitcoincharts.com/v1/csv/ есть много биржевых данных по криптовалютам, подойдет файл btceUSD.csv.gz; или по ссылке http://www.quantshare.com/sa-43-10-ways-to-download-historical-stock-quotes-data-for-free можно узнать как скачать биржевые котировки. Далее нужно использовать 2 алгоритма прогнозирования временных рядов (с использованием комбинации линейного или экспоненциального тренда, аддитивной или мультипликативной сезонности) и подобрать параметры алгоритмов дающих хорошую точность по предсказанию на 12 часов вперёд (для временных рядов с шагом в сутки использовать предсказание - на 4 дня вперёд). Выбрать наилучший алгоритм. Обосновать графически или иным нехудшим способом выбор модели и значений параметров.
Дополнительное необязательное задание, увеличивающее шансы на сдачу задачи: ответить на вопрос, удалось бы заработать, применяя полученный наилучший алгоритм прогнозирования?
Рекомендации по решению: биржевые котировки могут иметь пробелы и нерегулярный ход по временной шкале. Допустимо огрубить результаты так, чтобы ход точек был регулярный. Для заполнения пробелов можно использовать само прогнозирование. Стоит подумать над тем, что считать критерием наилучшего алгоритма.

Задача 5: Сгенерировать два случайных, частично перекрывающихся нормальных распределения для объектов на двумерном вещественном пространстве {R,R}, подобно задаче 1. Должны настраиваться: количество объектов класса 1 и класса 2, центры гауссовских распределений, ковариационные матрицы. Построить и обучить непараметрический байесовский классификатор с парзеновским окном, а также параметрический нормальный байесовский классификатор. Использовать методы контроля качества классификатора и с помощью них оптимизировать параметры классификатора. Нарисовать карту машинной классификации для области пространства, окружающей объекты. На карте двумя цветами или контурной линией должна быть отмечена зона отнесения к первому или второму классу. Поверх должны быть показаны объекты обучающей выборки соответствующим цветом.

Задача 6: Решить задачу классификации рукописных изображений цифр, взятых из http://yann.lecun.com/exdb/mnist/, с помощью двуслойной линейной нейронной сети. Функцию активации нейрона можно взять сигмоидальную. В задаче требуется реализовать нейронную сеть, а также алгоритм обратного распространения ошибки для её обучения. Для импорта данных из файлов написана готовая функция на Python, которую рекомендуется использовать. Её можно скачать по адресу: http://download.ximc.ru/Machine%20learning/ML%20-%20Task6-import.py . Обучить нейронную сеть до достижения <15% ошибок классификации на тестовой выборке. При этом считается, что на каждом тестовом объекте всегда одна из 10 цифр. Требуется только определить какая. Не обязательно использовать всю базу для обучения или проверки — можно выбрать любое репрезентативное подмножество. Использовать минимум одну из эвристик для улучшения обучения нейронной сети.

Задача 7: Модифицировать задачу 6, чтобы в алгоритме классификации использовалась композиция нейронных сетей с заметно меньшим количеством нейронов скрытого слоя. Использовать метод AdaBoost, SGB или ComBoost. При этом подразумевается, что придётся поменять подход к решению задачи многоклассовой классификации, а также принять часть решений, которые делают бустинг совместимым с нейронными сетями.

Задача 8: Решить задачу кластеризации над множеством объектов с двумерными действительными признаками {R,R}. Для этого должны генерироваться 3 случайных распределения с настраиваемыми параметрами. Как минимум одно с гауссовским распределением, настраиваемым центром и матрицей ковариации. Решить задачу методом агломеративной иерархической кластеризации или методом сетей Кохонена. Использовать визуализацию процесса поиска кластеров, показывая цветами текущее количество кластеров или их центров (в зависимости от метода) на двумерной плоскости. Итоговый формат представления данных это набор изображений, которые можно просматривать вперёд и назад. На изображениях нужно уметь добавлять текстовые параметры, такие как минимальное расстояние между кластерами или номер итерации.
